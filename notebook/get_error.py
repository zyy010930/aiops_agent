import json
import os
import time
from datetime import datetime, timedelta, timezone

from aliyun.log import LogClient, GetLogsRequest
from matplotlib import pyplot as plt

# SLS configuration
PROJECT_NAME = "proj-xtrace-a46b97cfdc1332238f714864c014a1b-cn-qingdao"
LOGSTORE_NAME = "logstore-tracing"
REGION = "cn-qingdao"

def read_input_data(input_file_path):
    """
    Read and parse input data from JSONL file

    Args:
        input_file_path: Path to the input JSONL file

    Returns:
        list: List of parsed JSON objects
    """
    data = []

    try:
        with open(input_file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line:  # Skip empty lines
                    try:
                        item = json.loads(line)
                        data.append(item)
                    except json.JSONDecodeError as e:
                        print(f"âš ï¸ Failed to parse line: {line[:100]}... Error: {e}")
                        continue

        print(f"âœ… Successfully read {len(data)} records from {input_file_path}")
        return data

    except FileNotFoundError:
        print(f"âŒ Input file not found: {input_file_path}")
        return []
    except Exception as e:
        print(f"âŒ Failed to read input file: {e}")
        return []

def datetime_to_timestamp(time_str):
    # è§£ææ—¶é—´å­—ç¬¦ä¸²ä¸ºdatetimeå¯¹è±¡ï¼ˆé»˜è®¤æœ¬åœ°æ—¶åŒºï¼Œå¦‚éœ€UTCå¯æŒ‡å®štzinfoï¼‰
    dt = datetime.strptime(time_str, "%Y-%m-%d %H:%M:%S")

    # è®¡ç®—ä¸epochæ—¶é—´çš„å·®å€¼ï¼ˆç§’ï¼‰ï¼Œå†è½¬æ¢ä¸ºæ¯«ç§’
    timestamp_ms = int(dt.timestamp() * 1000)

    print(timestamp_ms)  # è¾“å‡ºï¼š1758325449000
    return timestamp_ms

def dt_to_ms(dt):
    return int(dt.timestamp() * 1000)
def get_sts_credentials():
    try:
        from aliyunsdkcore.client import AcsClient
        from aliyunsdksts.request.v20150401 import AssumeRoleRequest

        MAIN_ACCOUNT_ACCESS_KEY_ID = os.getenv('ALIBABA_CLOUD_ACCESS_KEY_ID')
        MAIN_ACCOUNT_ACCESS_KEY_SECRET = os.getenv('ALIBABA_CLOUD_ACCESS_KEY_SECRET')
        ALIBABA_CLOUD_ROLE_ARN = os.getenv('ALIBABA_CLOUD_ROLE_ARN', 'acs:ram::1672753017899339:role/tianchi-user-a')
        STS_SESSION_NAME = os.getenv('ALIBABA_CLOUD_ROLE_SESSION_NAME', 'my-sls-access')

        if not MAIN_ACCOUNT_ACCESS_KEY_ID or not MAIN_ACCOUNT_ACCESS_KEY_SECRET:
            return None, None, None

        client = AcsClient(MAIN_ACCOUNT_ACCESS_KEY_ID, MAIN_ACCOUNT_ACCESS_KEY_SECRET, REGION)
        request = AssumeRoleRequest.AssumeRoleRequest()
        request.set_RoleArn(ALIBABA_CLOUD_ROLE_ARN)
        request.set_RoleSessionName(STS_SESSION_NAME)
        request.set_DurationSeconds(3600)

        response = client.do_action_with_exception(request)
        response_data = json.loads(response)
        credentials = response_data['Credentials']
        return (credentials['AccessKeyId'], credentials['AccessKeySecret'], credentials['SecurityToken'])
    except Exception as e:
        print(f"âŒ è·å–STSå‡­è¯å¤±è´¥: {e}")
        return None, None, None


temp_access_key_id, temp_access_key_secret, security_token = get_sts_credentials()
if not temp_access_key_id:
    print("âŒ æ— æ³•è·å–STSä¸´æ—¶å‡­è¯ï¼Œåˆ†æç»ˆæ­¢")

try:
    from aliyun.log import LogClient

    sls_endpoint = os.getenv("SLS_ENDPOINT", "cn-qingdao.log.aliyuncs.com")
    log_client = LogClient(sls_endpoint, temp_access_key_id, temp_access_key_secret, security_token)
except Exception as e:
    print(f"âŒ åˆ›å»ºSLSå®¢æˆ·ç«¯å¤±è´¥: {e}")

def get_errorInfo(log_client, project, logstore, service, start, end):
    """è·å–æŒ‡å®šæ—¶é—´æ®µå†…ç‰¹å®šèŠ‚ç‚¹ä¸Šå„hostnameçš„å¹³å‡duration"""
    start_dt = datetime.strptime(start, "%Y-%m-%d %H:%M:%S")
    end_dt = datetime.strptime(end, "%Y-%m-%d %H:%M:%S")
    start = int(start_dt.timestamp()) * 1000000000
    end = int(end_dt.timestamp()) * 1000000000

    # æ„å»ºæŸ¥è¯¢è¯­å¥ï¼Œç­›é€‰ç‰¹å®šèŠ‚ç‚¹å¹¶æŒ‰hostnameåˆ†ç»„
    query = f"""
    (serviceName : "{service}") AND statusCode>1
    | SELECT statusmessage as info FROM log group by info order by count(info) DESC LIMIT 0, 999 
    """
    print(query)
    request = GetLogsRequest(
        project=project,
        logstore=logstore,
        query=query,
        fromTime=start_dt.timestamp(),
        toTime=end_dt.timestamp()
    )
    response = log_client.get_logs(request)
    logs = response.get_logs()
    print(f"âœ… è·å–æ—¥å¿—æˆåŠŸï¼Œå…± {len(logs)} æ¡")
    print(logs[0].get_contents().get("info"))
    return logs[0].get_contents().get("info")

def get_span_error(log_client, project, logstore, service, start, end, isMedian=True):
    """è·å–æŒ‡å®šæ—¶é—´æ®µå†…ç‰¹å®šèŠ‚ç‚¹ä¸Šå„hostnameçš„å¹³å‡duration"""
    start_dt = datetime.strptime(start, "%Y-%m-%d %H:%M:%S")
    end_dt = datetime.strptime(end, "%Y-%m-%d %H:%M:%S")
    start_minus_5 = start_dt - timedelta(minutes=10)
    end_plus_5 = end_dt + timedelta(minutes=10)
    start_dt = start_dt - timedelta(minutes=1)
    end_dt = end_dt + timedelta(minutes=1)
    start_minus = int(start_minus_5.timestamp()) * 1000000000
    end_plus = int(end_plus_5.timestamp()) * 1000000000

    # æ„å»ºæŸ¥è¯¢è¯­å¥ï¼Œç­›é€‰ç‰¹å®šèŠ‚ç‚¹å¹¶æŒ‰hostnameåˆ†ç»„
    query = f"""
    (statusCode : 2 or statusCode : 3) and spanName : "grpc.oteldemo.CurrencyService/GetSupportedCurrencies" and attributes.grpc.error_message : "14 UNAVAILABLE: read ECONNRESET"
    | SELECT count(statusCode) as statusCode, (startTime/1000000 -startTime/1000000 %(15000 * 4)) as date FROM log GROUP BY date LIMIT 0, 999 
    """

    request = GetLogsRequest(
        project=project,
        logstore=logstore,
        query=query,
        fromTime=start_minus_5.timestamp(),
        toTime=end_plus_5.timestamp()
    )
    response = log_client.get_logs(request)
    logs = response.get_logs()
    print(f"âœ… è·å–æ—¥å¿—æˆåŠŸï¼Œå…± {len(logs)} æ¡")

    # æ ¸å¿ƒæ”¹è¿›ï¼šæŒ‰timeå­—æ®µçš„æ—¶é—´é¡ºåºæ’åº
    # 1. å…ˆå°†æ—¥å¿—è½¬æ¢ä¸ºåŒ…å«æ—¶é—´å’Œå€¼çš„å­—å…¸åˆ—è¡¨
    log_list = []
    for log in logs:
        contents = log.get_contents()
        print(contents)
        time_stamp_str = contents.get("date")  # æ¯«ç§’æ—¶é—´æˆ³å­—ç¬¦ä¸²ï¼Œå¦‚"1758326280000"
        avg_duration = contents.get("statusCode")

        if time_stamp_str and avg_duration:  # è¿‡æ»¤æ— æ•ˆæ•°æ®
            try:
                # è½¬æ¢ä¸ºæ•´æ•°å‹æ—¶é—´æˆ³ï¼ˆç¡®ä¿æ’åºå‡†ç¡®æ€§ï¼‰
                time_stamp = int(time_stamp_str)
                log_list.append({
                    "time_ms": time_stamp,
                    # åŒæ—¶è½¬æ¢ä¸ºå¯è¯»æ—¶é—´æ ¼å¼ï¼ˆç”¨äºxè½´æ˜¾ç¤ºï¼‰
                    "time_str": datetime.fromtimestamp(time_stamp / 1000).replace(tzinfo=timezone(timedelta(hours=8))).strftime("%Y-%m-%d %H:%M:%S"),
                    "statusCode": float(avg_duration)
                })
            except ValueError:
                print(f"âš ï¸ æ— æ•ˆçš„æ—¶é—´æˆ³æ ¼å¼: {time_stamp_str}ï¼Œå·²è·³è¿‡")
    # print(log_list)
    # æŒ‰æ—¶é—´æˆ³æ•°å€¼æ’åºï¼ˆä»å°åˆ°å¤§ï¼Œå³æ—¶é—´å…ˆåé¡ºåºï¼‰
    log_list.sort(key=lambda x: x["time_ms"])

    # 1. å®šä¹‰ä¸‰ä¸ªæ—¶æ®µçš„æ—¶é—´èŒƒå›´ï¼ˆæ¯«ç§’çº§ï¼‰
    # å‰5åˆ†é’Ÿï¼š[start_minus_5, start_dt)
    before_start_ms = dt_to_ms(start_minus_5)
    before_end_ms = dt_to_ms(start_dt)
    # ç›®æ ‡æ—¶æ®µï¼š[start_dt, end_dt)
    target_start_ms = dt_to_ms(start_dt)
    target_end_ms = dt_to_ms(end_dt)
    # å5åˆ†é’Ÿï¼š[end_dt, end_plus_5)
    after_start_ms = dt_to_ms(end_dt)
    after_end_ms = dt_to_ms(end_plus_5)

    # 2. æ•°æ®åˆ†ç»„åˆ°ä¸‰ä¸ªæ—¶æ®µ
    before_data = []  # å‰5åˆ†é’Ÿæ—¶å»¶
    target_data = []  # ç›®æ ‡æ—¶æ®µæ—¶å»¶
    after_data = []  # å5åˆ†é’Ÿæ—¶å»¶

    for item in log_list:
        ts = item["time_ms"]
        duration = item["statusCode"]
        if before_start_ms <= ts < before_end_ms:
            before_data.append(duration)
        elif target_start_ms <= ts < target_end_ms:
            target_data.append(duration)
        elif after_start_ms <= ts < after_end_ms:
            after_data.append(duration)

    # 3. è®¡ç®—å„æ—¶æ®µå¹³å‡é”™è¯¯æ•°é‡ï¼ˆä½¿ç”¨ä¸­ä½æ•°å¯å‡å°‘å¼‚å¸¸å€¼å½±å“ï¼‰
    def calc_statistic(data, is_median=True):
        if not data:
            return None
        if is_median:
            sorted_data = sorted(data)
            n = len(sorted_data)
            return sorted_data[n // 2] if n % 2 else (sorted_data[n // 2 - 1] + sorted_data[n // 2]) / 2
        return sum(data) / len(data)

    before_stat = calc_statistic(before_data, isMedian)  # å‰5åˆ†é’Ÿç»Ÿè®¡å€¼
    target_stat = calc_statistic(target_data, isMedian)  # ç›®æ ‡æ—¶æ®µç»Ÿè®¡å€¼
    after_stat = calc_statistic(after_data, isMedian)  # å5åˆ†é’Ÿç»Ÿè®¡å€¼

    # 4. è¾“å‡ºç»Ÿè®¡ç»“æœ
    print("\n=== æŠ¥é”™ç»Ÿè®¡å¯¹æ¯” ===")
    print(f"å‰5åˆ†é’Ÿï¼ˆ{start_minus_5.strftime('%H:%M:%S')}è‡³{start_dt.strftime('%H:%M:%S')}ï¼‰: "
          f"{before_stat:.2f}" if before_stat else "å‰5åˆ†é’Ÿæ— æ•°æ®")
    print(f"ç›®æ ‡æ—¶æ®µï¼ˆ{start}è‡³{end}ï¼‰: "
          f"{target_stat:.2f}" if target_stat else "ç›®æ ‡æ—¶æ®µæ— æ•°æ®")
    print(f"å5åˆ†é’Ÿï¼ˆ{end_dt.strftime('%H:%M:%S')}è‡³{end_plus_5.strftime('%H:%M:%S')}ï¼‰: "
          f"{after_stat:.2f}" if after_stat else "å5åˆ†é’Ÿæ— æ•°æ®")

    # 5. åˆ¤æ–­æ˜¯å¦æ˜æ˜¾ä¸Šå‡
    threshold = 1.5
    if target_stat and before_stat and after_stat:
        rise_ratio_before = (target_stat - before_stat) / before_stat * 100
        rise_ratio_after = (target_stat - after_stat) / after_stat * 100
        if target_stat > before_stat * threshold and target_stat > after_stat * threshold:
            print(
                f"\nâš ï¸ ç›®æ ‡æ—¶æ®µæŠ¥é”™ç›¸æ¯”å‰10åˆ†é’Ÿä¸Šå‡{rise_ratio_before:.1f}%ï¼Œç›¸æ¯”å10åˆ†é’Ÿä¸Šå‡{rise_ratio_after:.1f}%ï¼Œè¶…è¿‡{int((threshold - 1) * 100)}%ï¼Œå­˜åœ¨æ˜æ˜¾ä¸Šå‡ï¼")
            return True
        else:
            print(
                f"\nâœ… ç›®æ ‡æ—¶æ®µæŠ¥é”™ç›¸æ¯”å‰10åˆ†é’Ÿä¸Šå‡{rise_ratio_before:.1f}%ï¼Œç›¸æ¯”å10åˆ†é’Ÿä¸Šå‡{rise_ratio_after:.1f}%ï¼Œæœªè¶…è¿‡{int((threshold - 1) * 100)}%ï¼Œæ— æ˜æ˜¾ä¸Šå‡ã€‚")
    elif target_stat and (not before_stat or not after_stat):
        print(f"\nâš ï¸ å­˜åœ¨å¼‚å¸¸æŠ¥é”™ï¼Œè¯·æ£€æŸ¥æ—¥å¿—ã€‚")
        return True
    else:
        print("\nâš ï¸ æ•°æ®ä¸è¶³ï¼Œæ— æ³•åˆ¤æ–­æ—¶å»¶å˜åŒ–ã€‚")

    return False


def get_error(log_client, project, logstore, service, start, end, isMedian=True):
    """è·å–æŒ‡å®šæ—¶é—´æ®µå†…ç‰¹å®šèŠ‚ç‚¹ä¸Šå„hostnameçš„å¹³å‡duration"""
    start_dt = datetime.strptime(start, "%Y-%m-%d %H:%M:%S")
    end_dt = datetime.strptime(end, "%Y-%m-%d %H:%M:%S")
    # è®¡ç®—æ—¶é—´å·®ï¼ˆåˆ†é’Ÿä¸ºå•ä½ï¼Œå–æ•´æ•°ï¼‰
    time_diff_minutes = int((end_dt - start_dt).total_seconds() / 60)
    start_minus_5 = start_dt - timedelta(minutes=10)
    end_plus_5 = end_dt + timedelta(minutes=10)
    start_dt = start_dt - timedelta(minutes=1)
    end_dt = end_dt + timedelta(minutes=1)
    start_minus = int(start_minus_5.timestamp()) * 1000000000
    end_plus = int(end_plus_5.timestamp()) * 1000000000

    # æ„å»ºæŸ¥è¯¢è¯­å¥ï¼Œç­›é€‰ç‰¹å®šèŠ‚ç‚¹å¹¶æŒ‰hostnameåˆ†ç»„
    query = f"""
    ((serviceName : "{service}") AND startTime in [{start_minus} {end_plus})) AND statusCode>1
    | SELECT count(statusCode) as statusCode, (startTime/1000000 -startTime/1000000 %(15000 * 4)) as date FROM log GROUP BY date LIMIT 0, 999 
    """

    request = GetLogsRequest(
        project=project,
        logstore=logstore,
        query=query,
        fromTime=start_minus_5.timestamp(),
        toTime=end_plus_5.timestamp()
    )
    response = log_client.get_logs(request)
    logs = response.get_logs()
    print(f"âœ… è·å–æ—¥å¿—æˆåŠŸï¼Œå…± {len(logs)} æ¡")

    # æ ¸å¿ƒæ”¹è¿›ï¼šæŒ‰timeå­—æ®µçš„æ—¶é—´é¡ºåºæ’åº
    # 1. å…ˆå°†æ—¥å¿—è½¬æ¢ä¸ºåŒ…å«æ—¶é—´å’Œå€¼çš„å­—å…¸åˆ—è¡¨
    log_list = []
    for log in logs:
        contents = log.get_contents()
        #print(contents)
        time_stamp_str = contents.get("date")  # æ¯«ç§’æ—¶é—´æˆ³å­—ç¬¦ä¸²ï¼Œå¦‚"1758326280000"
        avg_duration = contents.get("statusCode")

        if time_stamp_str and avg_duration:  # è¿‡æ»¤æ— æ•ˆæ•°æ®
            try:
                # è½¬æ¢ä¸ºæ•´æ•°å‹æ—¶é—´æˆ³ï¼ˆç¡®ä¿æ’åºå‡†ç¡®æ€§ï¼‰
                time_stamp = int(time_stamp_str)
                log_list.append({
                    "time_ms": time_stamp,
                    # åŒæ—¶è½¬æ¢ä¸ºå¯è¯»æ—¶é—´æ ¼å¼ï¼ˆç”¨äºxè½´æ˜¾ç¤ºï¼‰
                    "time_str": datetime.fromtimestamp(time_stamp / 1000).replace(tzinfo=timezone(timedelta(hours=8))).strftime("%Y-%m-%d %H:%M:%S"),
                    "statusCode": float(avg_duration)
                })
            except ValueError:
                print(f"âš ï¸ æ— æ•ˆçš„æ—¶é—´æˆ³æ ¼å¼: {time_stamp_str}ï¼Œå·²è·³è¿‡")
    #print(log_list)
    # æŒ‰æ—¶é—´æˆ³æ•°å€¼æ’åºï¼ˆä»å°åˆ°å¤§ï¼Œå³æ—¶é—´å…ˆåé¡ºåºï¼‰
    log_list.sort(key=lambda x: x["time_ms"])

    # 1. å®šä¹‰ä¸‰ä¸ªæ—¶æ®µçš„æ—¶é—´èŒƒå›´ï¼ˆæ¯«ç§’çº§ï¼‰
    # å‰5åˆ†é’Ÿï¼š[start_minus_5, start_dt)
    before_start_ms = dt_to_ms(start_minus_5)
    before_end_ms = dt_to_ms(start_dt)
    # ç›®æ ‡æ—¶æ®µï¼š[start_dt, end_dt)
    target_start_ms = dt_to_ms(start_dt)
    target_end_ms = dt_to_ms(end_dt)
    # å5åˆ†é’Ÿï¼š[end_dt, end_plus_5)
    after_start_ms = dt_to_ms(end_dt)
    after_end_ms = dt_to_ms(end_plus_5)

    # 2. æ•°æ®åˆ†ç»„åˆ°ä¸‰ä¸ªæ—¶æ®µ
    before_data = []  # å‰5åˆ†é’Ÿæ—¶å»¶
    target_data = []  # ç›®æ ‡æ—¶æ®µæ—¶å»¶
    after_data = []  # å5åˆ†é’Ÿæ—¶å»¶

    for item in log_list:
        ts = item["time_ms"]
        duration = item["statusCode"]
        if before_start_ms <= ts < before_end_ms:
            before_data.append(duration)
        elif target_start_ms <= ts < target_end_ms:
            target_data.append(duration)
        elif after_start_ms <= ts < after_end_ms:
            after_data.append(duration)

    # 3. è®¡ç®—å„æ—¶æ®µå¹³å‡é”™è¯¯æ•°é‡ï¼ˆä½¿ç”¨ä¸­ä½æ•°å¯å‡å°‘å¼‚å¸¸å€¼å½±å“ï¼‰
    def calc_statistic(data, is_median=True):
        if not data:
            return None
        # if is_median:
        #     sorted_data = sorted(data)
        #     n = len(sorted_data)
        #     return sorted_data[n // 2] if n % 2 else (sorted_data[n // 2 - 1] + sorted_data[n // 2]) / 2
        return sum(data) / time_diff_minutes

    before_stat = calc_statistic(before_data, isMedian)  # å‰5åˆ†é’Ÿç»Ÿè®¡å€¼
    target_stat = calc_statistic(target_data, isMedian)  # ç›®æ ‡æ—¶æ®µç»Ÿè®¡å€¼
    after_stat = calc_statistic(after_data, isMedian)  # å5åˆ†é’Ÿç»Ÿè®¡å€¼

    # 4. è¾“å‡ºç»Ÿè®¡ç»“æœ
    print("\n=== æŠ¥é”™ç»Ÿè®¡å¯¹æ¯” ===")
    print(f"å‰5åˆ†é’Ÿï¼ˆ{start_minus_5.strftime('%H:%M:%S')}è‡³{start_dt.strftime('%H:%M:%S')}ï¼‰: "
          f"{before_stat:.2f}" if before_stat else "å‰5åˆ†é’Ÿæ— æ•°æ®")
    print(f"ç›®æ ‡æ—¶æ®µï¼ˆ{start}è‡³{end}ï¼‰: "
          f"{target_stat:.2f}" if target_stat else "ç›®æ ‡æ—¶æ®µæ— æ•°æ®")
    print(f"å5åˆ†é’Ÿï¼ˆ{end_dt.strftime('%H:%M:%S')}è‡³{end_plus_5.strftime('%H:%M:%S')}ï¼‰: "
          f"{after_stat:.2f}" if after_stat else "å5åˆ†é’Ÿæ— æ•°æ®")

    # 5. åˆ¤æ–­æ˜¯å¦æ˜æ˜¾ä¸Šå‡ï¼ˆé˜ˆå€¼å¯è°ƒæ•´ï¼Œè¿™é‡Œè®¾ä¸º50%ï¼‰
    threshold = 1.5  # è¶…è¿‡å‰5åˆ†é’Ÿçš„1.5å€è§†ä¸ºæ˜æ˜¾ä¸Šå‡
    if target_stat and before_stat and after_stat:
        rise_ratio_before = (target_stat - before_stat) / before_stat * 100
        rise_ratio_after = (target_stat - after_stat) / after_stat * 100
        if target_stat > before_stat * threshold and target_stat > after_stat * threshold:
            print(f"\nâš ï¸ ç›®æ ‡æ—¶æ®µæŠ¥é”™ç›¸æ¯”å‰10åˆ†é’Ÿä¸Šå‡{rise_ratio_before:.1f}%ï¼Œç›¸æ¯”å10åˆ†é’Ÿä¸Šå‡{rise_ratio_after:.1f}%ï¼Œè¶…è¿‡{int((threshold - 1) * 100)}%ï¼Œå­˜åœ¨æ˜æ˜¾ä¸Šå‡ï¼")
            return True, before_stat, target_stat, after_stat
        else:
            print(f"\nâœ… ç›®æ ‡æ—¶æ®µæŠ¥é”™ç›¸æ¯”å‰10åˆ†é’Ÿä¸Šå‡{rise_ratio_before:.1f}%ï¼Œç›¸æ¯”å10åˆ†é’Ÿä¸Šå‡{rise_ratio_after:.1f}%ï¼Œæœªè¶…è¿‡{int((threshold - 1) * 100)}%ï¼Œæ— æ˜æ˜¾ä¸Šå‡ã€‚")
    elif target_stat and (not before_stat or not after_stat):
        print(f"\nâš ï¸ å­˜åœ¨å¼‚å¸¸æŠ¥é”™ï¼Œè¯·æ£€æŸ¥æ—¥å¿—ã€‚")
        return True, before_stat, target_stat, after_stat
    else:
        print("\nâš ï¸ æ•°æ®ä¸è¶³ï¼Œæ— æ³•åˆ¤æ–­æ—¶å»¶å˜åŒ–ã€‚")



    # # 6. å¯è§†åŒ–ï¼ˆæ ‡è®°ä¸‰ä¸ªæ—¶æ®µï¼‰
    # plt.figure(figsize=(12, 6))
    # x_dt = [datetime.strptime(item["time_str"], "%Y-%m-%d %H:%M:%S") for item in log_list]
    # y = [item["statusCode"] for item in log_list]
    # print(x_dt)
    # print(y)
    #
    # plt.plot(x_dt, y, marker='o', linestyle='-', color='b')
    # # ç”¨é˜´å½±æ ‡è®°ä¸‰ä¸ªæ—¶æ®µ
    # plt.axvspan(start_minus_5, start_dt, color='lightgreen', alpha=0.3, label='å‰5åˆ†é’Ÿ')
    # plt.axvspan(start_dt, end_dt, color='lightcoral', alpha=0.3, label='ç›®æ ‡æ—¶æ®µ')
    # plt.axvspan(end_dt, end_plus_5, color='lightblue', alpha=0.3, label='å5åˆ†é’Ÿ')
    #
    # # æ˜¾ç¤ºå›¾è¡¨
    # plt.show()
    return False, before_stat, target_stat, after_stat

if __name__ == "__main__":
    serveice_list = []
    problem_id = "040"
    input_data = read_input_data("../input.jsonl")
    for problem_data in input_data:
        if problem_data.get("problem_id") == problem_id:
            print(f"ğŸ” Found problem {problem_id}, processing...")
            problem_id = problem_data.get("problem_id", "unknown")
            time_range = problem_data.get("time_range", "")
            candidate_root_causes = problem_data.get("candidate_root_causes", [])
            alarm_rules = problem_data.get("alarm_rules", [])

            start_time, end_time = time_range.split(' ~ ')
            start_time = start_time.strip()
            end_time = end_time.strip()
            flag = get_error(log_client, PROJECT_NAME, LOGSTORE_NAME, "ad", start_time, end_time)
            # flag = get_span_error(log_client, PROJECT_NAME, LOGSTORE_NAME, "currency", start_time, end_time)
            # get_errorInfo(log_client, PROJECT_NAME, LOGSTORE_NAME, "cart", start_time, end_time)
    #         for candidate in candidate_root_causes:
    #             if '.' in candidate and candidate.endswith('.cpu'):
    #                 service = candidate.split('.')[0]
    #                 if service[1] == '-' or service == "image-provider" or service == "load-generator":
    #                     continue
    #                 print(f"ğŸ¯ Limiting analysis to candidate service: {service}")
    #                 flag = get_log(log_client, PROJECT_NAME, LOGSTORE_NAME, service, start_time, end_time)
    #                 if flag:
    #                     serveice_list.append(service)
    # print(serveice_list)
import json
import os
import argparse
from collections import defaultdict
from datetime import datetime, timezone, timedelta
from typing import Dict, Set, List, Any
from concurrent.futures import ThreadPoolExecutor, as_completed

import numpy as np
from openai import OpenAI

from get_entity import analyze_cpu, analyze_memory, get_pod
from get_log import read_input_data, get_log, get_span_latency
from get_ecs import analyze_ecs_memory, analyze_ecs_cpu, analyze_ecs_disk
from get_error import get_error, get_span_error, get_errorInfo
from get_instance import get_instance
from get_prom import analyze_network, analyze_gc

# SLS configuration
PROJECT_NAME = "proj-xtrace-a46b97cfdc1332238f714864c014a1b-cn-qingdao"
LOGSTORE_NAME = "logstore-tracing"
REGION = "cn-qingdao"

def call_bailian_model(root_causes: List[str], root_cause_data: Dict[str, Any]) -> str:
    final_root_causes = []
    """
    è°ƒç”¨é˜¿é‡Œäº‘ç™¾ç‚¼å¤§æ¨¡å‹æ¥å£ï¼Œä»å¤šä¸ªæ ¹å› ä¸­ç­›é€‰æœ€å¯èƒ½çš„ç»“æœ
    """
    client = OpenAI(
        # è‹¥æ²¡æœ‰é…ç½®ç¯å¢ƒå˜é‡ï¼Œè¯·ç”¨ç™¾ç‚¼API Keyå°†ä¸‹è¡Œæ›¿æ¢ä¸ºï¼šapi_key="sk-xxx",
        api_key=os.getenv("BAILIAN_API_KEY"),
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    )

    # æ„é€ æ ¹å› æ•°æ®å­—ç¬¦ä¸²
    cause_data_str = ""
    for cause in root_causes:
        if cause in root_cause_data:
            cause_data_str += f"- {cause} çš„è¯¦ç»†æ•°æ®: {json.dumps(root_cause_data[cause], ensure_ascii=False, default=str)}\n"

    # æ„é€ æç¤ºè¯ï¼ŒåŒ…å«æ ¹å› æ•°æ®ï¼Œç”±äºæ•°æ®é‡‡æ ·åŒ…å«å¼‚å¸¸æ—¶é—´æ®µçš„å‰ååˆ†é’Ÿå’Œåååˆ†é’Ÿï¼Œå› æ­¤æç¤ºè¯ä¸­éœ€è¦è¯´æ˜å¼‚å¸¸æ—¶é—´æ®µå¸®åŠ©é€‰æ‹©å‡ºæœ€ç¬¦åˆæ—¶é—´çš„æ ¹å› ã€‚
    prompt = f"""
           è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ä»å€™é€‰æ ¹å› ä¸­é€‰æ‹©æœ€å¯èƒ½çš„ä¸€ä¸ªï¼š

           å€™é€‰æ ¹å› åˆ—è¡¨ï¼ˆæ ¼å¼ä¸º"æœåŠ¡å.æ•…éšœç±»å‹"ï¼‰ï¼š
           {json.dumps(root_causes, ensure_ascii=False)}

           å„å€™é€‰æ ¹å› çš„è¯¦ç»†æ•°æ®ï¼š
           {cause_data_str}
           
           å¼‚å¸¸ä¸Šå‡è¶‹åŠ¿å¼€å§‹äºç¬¬åä¸€ä¸ªç‚¹ä»¥åçš„æ›´å¯èƒ½æ˜¯æ ¹å› ï¼Œå¼‚å¸¸ä¸Šå‡å¼€å§‹äºç¬¬åä¸ªç‚¹ä¹‹å‰çš„å¯ä»¥é™ä½ä¼˜å…ˆçº§ï¼Œå¼‚å¸¸å»¶ç»­åˆ°å€’æ•°ç¬¬å…­ä¸ªç‚¹ç»“æŸçš„æ›´å¯èƒ½æ˜¯æ ¹å› ï¼Œæ—©äºè¯¥ç‚¹çš„å¯ä»¥é™ä½ä¼˜å…ˆçº§ã€‚

           è¯·ç»“åˆæ ¹å› çš„æ•°æ®ï¼Œæ ¹æ®å¼‚å¸¸æ—¶é—´èµ·ç‚¹å’Œæ ¹å› æ•°æ®å¼‚å¸¸å®é™…èµ·ç‚¹ï¼Œåˆ†æå“ªä¸ªæ ¹å› æœ€å¯èƒ½æ˜¯é—®é¢˜çš„æºå¤´ã€‚
           è¦æ±‚ï¼šåªè¿”å›é€‰ä¸­çš„æ ¹å› å­—ç¬¦ä¸²ï¼Œä¸è¦é¢å¤–è§£é‡Šã€‚
           """
    print(f"prompt: {prompt}")

    completion = client.chat.completions.create(
        model="kimi-k2-thinking",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªåˆ†å¸ƒå¼ç³»ç»Ÿæ•…éšœè¯Šæ–­ä¸“å®¶"},
            {"role": "user", "content": f"{prompt}"},
        ],
        stream=True
    )
    causes = ""
    for chunk in completion:
        if chunk.choices[0].delta.content:
            print(chunk.choices[0].delta.content, end="", flush=True)
            causes += chunk.choices[0].delta.content

    return causes.strip()

def get_sts_credentials():
    try:
        from aliyunsdkcore.client import AcsClient
        from aliyunsdksts.request.v20150401 import AssumeRoleRequest

        MAIN_ACCOUNT_ACCESS_KEY_ID = os.getenv('ALIBABA_CLOUD_ACCESS_KEY_ID')
        MAIN_ACCOUNT_ACCESS_KEY_SECRET = os.getenv('ALIBABA_CLOUD_ACCESS_KEY_SECRET')
        ALIBABA_CLOUD_ROLE_ARN = os.getenv('ALIBABA_CLOUD_ROLE_ARN', 'acs:ram::1672753017899339:role/tianchi-user-a')
        STS_SESSION_NAME = os.getenv('ALIBABA_CLOUD_ROLE_SESSION_NAME', 'my-sls-access')

        if not MAIN_ACCOUNT_ACCESS_KEY_ID or not MAIN_ACCOUNT_ACCESS_KEY_SECRET:
            return None, None, None

        client = AcsClient(MAIN_ACCOUNT_ACCESS_KEY_ID, MAIN_ACCOUNT_ACCESS_KEY_SECRET, REGION)
        request = AssumeRoleRequest.AssumeRoleRequest()
        request.set_RoleArn(ALIBABA_CLOUD_ROLE_ARN)
        request.set_RoleSessionName(STS_SESSION_NAME)
        request.set_DurationSeconds(3600)

        response = client.do_action_with_exception(request)
        response_data = json.loads(response)
        credentials = response_data['Credentials']
        return (credentials['AccessKeyId'], credentials['AccessKeySecret'], credentials['SecurityToken'])
    except Exception as e:
        print(f"âŒ è·å–STSå‡­è¯å¤±è´¥: {e}")
        return None, None, None


temp_access_key_id, temp_access_key_secret, security_token = get_sts_credentials()
if not temp_access_key_id:
    print("âŒ æ— æ³•è·å–STSä¸´æ—¶å‡­è¯ï¼Œåˆ†æç»ˆæ­¢")

try:
    from aliyun.log import LogClient

    sls_endpoint = f"{REGION}.log.aliyuncs.com"
    log_client = LogClient(sls_endpoint, temp_access_key_id, temp_access_key_secret, security_token)
except Exception as e:
    print(f"âŒ åˆ›å»ºSLSå®¢æˆ·ç«¯å¤±è´¥: {e}")

# å®šä¹‰æ‰€æœ‰è°ƒç”¨å…³ç³»ï¼š(è°ƒç”¨æ–¹, è¢«è°ƒç”¨æ–¹)
calls_relations = [
    ("load-generator", "frontend-proxy"),
    ("frontend-web", "frontend-proxy"),
    ("frontend-proxy", "image-provider"),
    ("frontend-proxy", "frontend"),
    ("frontend", "ad"),
    ("frontend", "recommendation"),
    ("frontend", "product-catalog"),
    ("frontend", "checkout"),
    ("frontend", "cart"),
    ("frontend", "currency"),
    ("recommendation", "product-catalog"),
    ("cart", "inventory"),
    ("checkout", "product-catalog"),
    ("checkout", "cart"),
    ("checkout", "payment"),
    ("checkout", "shipping"),
    ("checkout", "email"),
    ("checkout", "currency"),
    ("shipping", "quote"),
]

# åˆå§‹åŒ–ä¸Šæ¸¸æœåŠ¡å­—å…¸
service_upstreams = {}
all_services = set()

# æ”¶é›†æ‰€æœ‰æœåŠ¡
for caller, callee in calls_relations:
    all_services.add(caller)
    all_services.add(callee)

# è¿‡æ»¤æ‰éåº”ç”¨æœåŠ¡ï¼ˆæ•°æ®åº“ã€æ¶ˆæ¯æœåŠ¡ç­‰ï¼‰
app_services = [s for s in all_services if not (s.startswith("rm-") or s.startswith("r-") or s == "orders")]

# åˆå§‹åŒ–åº”ç”¨æœåŠ¡çš„ä¸Šæ¸¸åˆ—è¡¨
for service in app_services:
    service_upstreams[service] = []

# å¡«å……ä¸Šæ¸¸åº”ç”¨
for caller, callee in calls_relations:
    if callee in app_services:  # åªè®°å½•åº”ç”¨æœåŠ¡çš„ä¸Šæ¸¸
        service_upstreams[callee].append(caller)


def get_only_anomaly(anomaly_list, root_causes, evidences_dict):
    amplitude_dict = {}
    for anomaly in anomaly_list:
        service = anomaly['service']
        if service + '.networkLatency' not in root_causes:
            continue
        # å‡è®¾beforeã€targetä¸ºæ•°å€¼åˆ—è¡¨ï¼Œå–å¹³å‡å€¼è®¡ç®—
        try:
            before = anomaly['before']
            after = anomaly['after']
            target = anomaly['target']
            amplitude = (target - before) / before + (target - after) / after  # ç›¸å¯¹å¢å¹…
            amplitude_dict[service] = amplitude
            print(f"ğŸ“Š {service} ä¸Šå‡å¹…åº¦: {amplitude:.2f}x")
            # è®°å½•è¯æ®
            evidence = f"{service}çš„ç½‘ç»œå»¶è¿Ÿå­˜åœ¨å¼‚å¸¸ï¼Œå¼‚å¸¸å€¼ä¸º{target}ï¼Œç›¸æ¯”æ­£å¸¸åŒºé—´å‰åŠæ®µ({before})å’ŒååŠæ®µ({after})çš„å¢å¹…ä¸º{amplitude:.2f}x"
            evidences_dict[service + '.networkLatency'].append(evidence)
        except Exception as e:
            print(f"âŒ è®¡ç®—{service}å¹…åº¦å¤±è´¥: {e}")

    if amplitude_dict:
        # æ‰¾åˆ°å¹…åº¦æœ€å¤§çš„æœåŠ¡
        max_amplitude_service = max(amplitude_dict.items(), key=lambda x: x[1])[0]
        # åªä¿ç•™è¯¥æœåŠ¡çš„æ ¹å› 
        root_causes = [item for item in root_causes if item.split('.')[0] == max_amplitude_service]
        # æ·»åŠ ç­›é€‰è¯æ®
        for cause in root_causes:
            evidences_dict[cause].append(f"é€šè¿‡è®¡ç®—å¼‚å¸¸å¹…åº¦ï¼Œ{cause.split('.')[0]}çš„å¼‚å¸¸å¹…åº¦æœ€å¤§ï¼Œè¢«é€‰ä¸ºä¸»è¦æ ¹å› ")
        print(f"ğŸ¯ æŒ‰æœ€å¤§ä¸Šå‡å¹…åº¦ç­›é€‰åçš„æ ¹å› : {root_causes}")
    return root_causes, evidences_dict


def get_frequency(cpu_list, memory_list, latency_candidates, jvm_list):
    # -------------------------- æ–°å¢ç»Ÿè®¡é€»è¾‘ --------------------------
    # 1. åˆå§‹åŒ–è®¡æ•°å™¨ï¼Œç”¨äºç»Ÿè®¡æ¯ä¸ªserviceçš„å‡ºç°æ¬¡æ•°
    service_counts = defaultdict(int)

    # 2. ä»ä¸‰ä¸ªåˆ—è¡¨ä¸­æå–serviceå¹¶ç»Ÿè®¡é¢‘ç‡
    # å¤„ç†cpu_listï¼ˆå…ƒç´ æ ¼å¼ï¼š"service.cpu"ï¼‰
    for item in cpu_list:
        service = item.split('.')[0]  # æå–serviceåç§°
        service_counts[service] += 1

    # å¤„ç†memory_listï¼ˆå…ƒç´ æ ¼å¼ï¼š"service.memory"ï¼‰
    for item in memory_list:
        service = item.split('.')[0]
        service_counts[service] += 1

    # å¤„ç†latency_candidatesï¼ˆå…ƒç´ æ ¼å¼ï¼š"service.networkLatency"ï¼‰
    for item in latency_candidates:
        service = item.split('.')[0]
        service_counts[service] += 1

    # å¤„ç†jvm_listï¼ˆå…ƒç´ æ ¼å¼ï¼š"service.jvm"ï¼‰
    for item in jvm_list:
        service = item.split('.')[0]
        service_counts[service] += 1

    # 3. ç­›é€‰å‡ºç°é¢‘ç‡æœ€é«˜çš„serviceï¼ˆè‹¥æœ‰å¤šä¸ªåˆ™å…¨éƒ¨ä¿ç•™ï¼‰
    if service_counts:  # é¿å…ç©ºåˆ—è¡¨å¯¼è‡´çš„é”™è¯¯
        max_frequency = max(service_counts.values())  # è·å–æœ€é«˜é¢‘ç‡
        # ç­›é€‰æ‰€æœ‰é¢‘ç‡ç­‰äºæœ€é«˜é¢‘ç‡çš„service
        most_frequent_services = [
            service for service, count in service_counts.items()
            if count == max_frequency
        ]
    else:
        most_frequent_services = []  # è‹¥ä¸‰ä¸ªåˆ—è¡¨éƒ½ä¸ºç©ºï¼Œè¿”å›ç©ºåˆ—è¡¨

    # 4. è¾“å‡ºç»“æœ
    print("\nç»Ÿè®¡ç»“æœï¼š")
    if most_frequent_services:
        print(f"å‡ºç°é¢‘ç‡æœ€é«˜çš„service(s)ï¼ˆé¢‘ç‡ï¼š{max_frequency}ï¼‰ï¼š{most_frequent_services}")
    else:
        print("ä¸‰ä¸ªåˆ—è¡¨å‡ä¸ºç©ºï¼Œæ— serviceå¯ç»Ÿè®¡")

    return most_frequent_services


def find_anomalies(root_list, root_cause_data, m=5, threshold_factor=3, consecutive=3):
    """
    æ‰¾å‡ºæ—¶é—´åºåˆ—ä¸­å¼‚å¸¸çš„å¼€å§‹ç‚¹ã€ç»“æŸç‚¹å’Œæœ€é«˜ç‚¹

    å‚æ•°:
        time_series (dict): åŒ…å«'cpu_data'å’Œ'memory_data'çš„å­—å…¸ï¼Œå€¼ä¸ºæ—¶é—´åºåˆ—åˆ—è¡¨
        m (int): è®¡ç®—åŸºçº¿å·®å¼‚çš„å‰mä¸ªç‚¹æ•°é‡ï¼Œé»˜è®¤5
        threshold_factor (int): é˜ˆå€¼å€æ•°ï¼Œé»˜è®¤3ï¼ˆå³åŸºçº¿å‡å€¼+3*æ ‡å‡†å·®ï¼‰
        consecutive (int): è¿ç»­å¤šå°‘ä¸ªå·®å¼‚ä½äºé˜ˆå€¼è§†ä¸ºå¼‚å¸¸ç»“æŸï¼Œé»˜è®¤3

    è¿”å›:
        dict: åŒ…å«'cpu'å’Œ'memory'çš„å¼‚å¸¸ä¿¡æ¯ï¼Œæ¯ä¸ªåŒ…å«'start'ï¼ˆå¼€å§‹ç´¢å¼•ï¼‰ã€'end'ï¼ˆç»“æŸç´¢å¼•ï¼‰ã€
              'peak'ï¼ˆæœ€é«˜ç‚¹å€¼ï¼‰ã€'peak_index'ï¼ˆæœ€é«˜ç‚¹ç´¢å¼•ï¼‰
    """
    results = {}
    seriesLen = 0
    for root_causes in root_list:
        data = root_cause_data[root_causes]['cpu_data']
        seriesLen = len(data)

        n = len(data)
        if n < 2:
            results[root_causes] = None  # å»æ‰'_data'åç¼€
            continue

        # è®¡ç®—ç›¸é‚»æ•°æ®ç‚¹çš„ç»å¯¹å·®å¼‚
        diff_abs = [abs(data[i + 1] - data[i]) for i in range(n - 1)]
        if len(diff_abs) < m:
            results[root_causes] = None
            continue

        # è®¡ç®—åŸºçº¿å·®å¼‚çš„å‡å€¼å’Œæ ‡å‡†å·®ï¼ˆå‰mä¸ªå·®å¼‚ï¼‰
        baseline_diff = diff_abs[:m]
        mu_diff = np.mean(baseline_diff)
        sigma_diff = np.std(baseline_diff)
        start_threshold = mu_diff + threshold_factor * sigma_diff

        # å¯»æ‰¾å¼‚å¸¸å¼€å§‹ç‚¹ï¼šç¬¬ä¸€ä¸ªè¶…è¿‡é˜ˆå€¼çš„å·®å¼‚å¯¹åº”çš„åä¸€ä¸ªæ•°æ®ç‚¹
        start_idx = None
        for i in range(m, len(diff_abs)):  # ä»ç¬¬mä¸ªå·®å¼‚å¼€å§‹æ£€æŸ¥
            if diff_abs[i] > start_threshold:
                start_idx = i + 1  # å·®å¼‚iå¯¹åº”data[i]åˆ°data[i+1]ï¼Œå¼‚å¸¸å¼€å§‹äºi+1
                break

        if start_idx is None:  # æ— å¼‚å¸¸å¼€å§‹ç‚¹
            results[root_causes] = {
                'start': None,
                'end': None,
                'peak': None,
                'peak_index': None
            }
            continue

        # å¯»æ‰¾å¼‚å¸¸ç»“æŸç‚¹ï¼šè¿ç»­consecutiveä¸ªå·®å¼‚ä½äºé˜ˆå€¼æ—¶ï¼Œå–æœ€åä¸€ä¸ªå·®å¼‚å¯¹åº”çš„åä¸€ä¸ªæ•°æ®ç‚¹
        end_idx = n - 1  # é»˜è®¤ç»“æŸäºæœ€åä¸€ä¸ªç‚¹
        current_consecutive = 0
        for i in range(start_idx - 1, len(diff_abs)):  # iæ˜¯diff_absçš„ç´¢å¼•
            if diff_abs[i] <= start_threshold:
                current_consecutive += 1
                if current_consecutive >= consecutive:
                    end_idx = i + 1  # ç»“æŸç‚¹ä¸ºi+1ï¼ˆdataçš„ç´¢å¼•ï¼‰
                    break
            else:
                current_consecutive = 0  # ä¸è¿ç»­åˆ™é‡ç½®è®¡æ•°

        # æå–å¼‚å¸¸åŒºé—´æ•°æ®å¹¶æ‰¾åˆ°æœ€é«˜ç‚¹
        anomaly_data = data[start_idx:end_idx + 1]  # åŒ…å«end_idx
        if not anomaly_data:
            peak = None
            peak_index = None
        else:
            peak = max(anomaly_data)
            peak_index = start_idx + anomaly_data.index(peak)

        # å­˜å‚¨ç»“æœ
        results[root_causes] = {
            'start': start_idx,
            'end': end_idx,
            'peak': peak,
            'peak_index': peak_index
        }
    print(results)
    final_list = []
    for root_causes, result in results.items():
        print(f"å¼‚å¸¸æ ¹å› ï¼š{root_causes}")
        print(f"å¼‚å¸¸å¼€å§‹ç‚¹ç´¢å¼•ï¼š{result['start']}")
        print(f"å¼‚å¸¸ç»“æŸç‚¹ç´¢å¼•ï¼š{result['end']}")
        print(f"å¼‚å¸¸åŒºé—´æœ€é«˜ç‚¹å€¼ï¼š{result['peak']}")
        print(f"å¼‚å¸¸åŒºé—´æœ€é«˜ç‚¹ç´¢å¼•ï¼š{result['peak_index']}")
        # åˆ¤æ–­å¼‚å¸¸ä¸Šå‡åŒºé—´æ˜¯å¦åœ¨æ­£å¸¸åŒºé—´å†…ï¼Œå¦‚æœè¶…å‡ºåŒºé—´åˆ™å¿½ç•¥
        if (result['peak_index'] is not None and result['peak_index'] <= 12) or (
                result['start'] is not None and result['start'] <= 8):
            continue
        final_list.append(root_causes)

    return final_list


# å¤„ç†å»¶è¿Ÿé—®é¢˜
def analyze_latency_problem(normal_start, normal_end, candidate_root_causes):
    anomaly_list: List[Dict[str, Any]] = []
    show = False
    latency = False
    cpu_list = []
    memory_list = []
    serveice_list = []
    combined = []
    latency_candidates = []  # ä¸´æ—¶å­˜å‚¨æ‰€æœ‰latencyå€™é€‰æœåŠ¡
    root_cause_data = {}  # æ–°å¢ï¼šå­˜å‚¨æ ¹å› æ•°æ®çš„å­—å…¸
    evidences_dict = defaultdict(list)  # å­˜å‚¨æ¯ä¸ªæ ¹å› çš„è¯æ®
    start_str = normal_start.replace(tzinfo=timezone(timedelta(hours=8))).strftime('%Y-%m-%d %H:%M:%S')
    end_str = normal_end.replace(tzinfo=timezone(timedelta(hours=8))).strftime('%Y-%m-%d %H:%M:%S')

    def process_one_service(service, normal_start, normal_end, isMedian=True):
        result = {
            'service': service,
            'cpu_anomaly': False,
            'memory_anomaly': False,
            'latency_anomaly': False,
            'anomaly_data': None,
            'cpu_data': None,  # å­˜å‚¨CPUåŸå§‹æ•°æ®
            'max_cpu': 0,  # å­˜å‚¨æœ€å¤§CPUå€¼
            'memory_data': None,  # å­˜å‚¨å†…å­˜åŸå§‹æ•°æ®
            'max_memory': 0,  # å­˜å‚¨æœ€å¤§å†…å­˜å€¼
            'latency_data': None  # å­˜å‚¨å»¶è¿Ÿæ•°æ®
        }
        print(f"ğŸ¯ Limiting analysis to candidate service: {service}")

        # 1. æŸ¥è¯¢CPUæ•°æ®
        print(f"ğŸ” æŸ¥è¯¢ {service} æœåŠ¡CPUæ•°æ®...")
        cpu_anomaly, max_cpu, cpu_data = analyze_cpu(normal_start, normal_end, service, show)
        result['cpu_data'] = cpu_data
        result['max_cpu'] = max_cpu
        if cpu_anomaly and max_cpu > 30.0:
            # è®°å½•CPUå¼‚å¸¸è¯æ®
            evidences_dict[service + '.cpu'].append(
                f"{service}çš„CPUä½¿ç”¨ç‡å‡ºç°å¼‚å¸¸ï¼Œæœ€å¤§å€¼è¾¾åˆ°{max_cpu}%"
            )
            result['cpu_anomaly'] = True

        # 2. æŸ¥è¯¢Memoryæ•°æ®
        print(f"ğŸ” æŸ¥è¯¢ {service} æœåŠ¡Memoryæ•°æ®...")
        if service == "email":
            result['memory_anomaly'] = False
            result['memory_data'] = []
            result['latency_anomaly'] = False
            result['latency_data'] = []
            return result

            # 2. æŸ¥è¯¢Memoryæ•°æ®
        memory_anomaly, max_memory, memory_data = analyze_memory(normal_start, normal_end, service, show)
        result['memory_data'] = memory_data
        result['max_memory'] = max_memory
        if memory_anomaly and max_memory > 25.0:
            # è®°å½•å†…å­˜å¼‚å¸¸è¯æ®
            evidences_dict[service + '.memory'].append(
                f"{service}çš„å†…å­˜ä½¿ç”¨ç‡å‡ºç°å¼‚å¸¸ï¼Œæœ€å¤§å€¼è¾¾åˆ°{max_memory}%"
            )
            result['memory_anomaly'] = True

        # 3. è·å–å»¶è¿Ÿæ•°æ®
        print(f"ğŸ¯ Limiting analysis to candidate service: {service}")
        flag, before, target, after, duration_data = get_log(log_client, PROJECT_NAME, LOGSTORE_NAME, service, start_str.strip(),
                                              end_str.strip(), isMedian)
        result['latency_data'] = duration_data
        if flag:
            result['latency_anomaly'] = True
            result['anomaly_data'] = {
                "service": service,
                "before": before,
                "target": target,
                "after": after,
            }
            # è®°å½•å»¶è¿Ÿå¼‚å¸¸è¯æ®
            evidences_dict[service + '.networkLatency'].append(
                f"{service}çš„ç½‘ç»œå»¶è¿Ÿå‡ºç°å¼‚å¸¸ï¼Œå¼‚å¸¸å€¼ä¸º{target}ï¼Œæ­£å¸¸åŒºé—´å‰åŠæ®µä¸º{before}ï¼ŒååŠæ®µä¸º{after}"
            )
        return result

    # å¹¶è¡Œ
    total_services = []
    for candidate in candidate_root_causes:
        if '.' in candidate and candidate.endswith('.cpu'):
            service = candidate.split('.')[0]
            if service[1] == '-' or service == "load-generator":
                continue
            total_services.append(service)

    with ThreadPoolExecutor() as executor:
        futures = [
            executor.submit(process_one_service, service, normal_start, normal_end) for service in total_services
        ]
        for future in as_completed(futures):
            result = future.result()
            service_name = result['service']
            if result['cpu_anomaly']:
                cpu_item = service_name + '.cpu'
                cpu_list.append(cpu_item)
                # å­˜å‚¨CPUæ ¹å› æ•°æ®
                root_cause_data[cpu_item] = {
                    'cpu_data': result['cpu_data'],
                    'memory_data': result['memory_data'],
                    'duration_data': result['latency_data']
                }
            if result['memory_anomaly']:
                memory_item = service_name + '.memory'
                memory_list.append(memory_item)
                # å­˜å‚¨å†…å­˜æ ¹å› æ•°æ®
                root_cause_data[memory_item] = {
                    'cpu_data': result['cpu_data'],
                    'memory_data': result['memory_data'],
                    'duration_data': result['latency_data']
                }
            if result['latency_anomaly']:
                latency_item = service_name + '.networkLatency'
                latency_candidates.append(latency_item)
                anomaly_list.append(result['anomaly_data'])
                # å­˜å‚¨å»¶è¿Ÿæ ¹å› æ•°æ®
                root_cause_data[latency_item] = {
                    'duration_data': result['latency_data']
                }

    if cpu_list == [] and memory_list == [] and latency_candidates == []:
        print("æ”¾å®½å¼‚å¸¸æ£€æµ‹è¦æ±‚ï¼Œæ”¹ç”¨å¹³å‡å€¼")
        total_services = []
        for candidate in candidate_root_causes:
            if '.' in candidate and candidate.endswith('.cpu'):
                service = candidate.split('.')[0]
                if service[1] == '-' or service == "load-generator":
                    continue
                total_services.append(service)

        with ThreadPoolExecutor() as executor:
            futures = [
                executor.submit(process_one_service, service, normal_start, normal_end, False) for service in
                total_services
            ]
            for future in as_completed(futures):
                result = future.result()
                service_name = result['service']
                if result['cpu_anomaly']:
                    cpu_item = service_name + '.cpu'
                    cpu_list.append(cpu_item)
                    # å­˜å‚¨CPUæ ¹å› æ•°æ®
                    root_cause_data[cpu_item] = {
                        'cpu_data': result['cpu_data'],
                        'memory_data': result['memory_data'],
                        'duration_data': result['latency_data']
                    }
                if result['memory_anomaly']:
                    memory_item = service_name + '.memory'
                    memory_list.append(memory_item)
                    # å­˜å‚¨å†…å­˜æ ¹å› æ•°æ®
                    root_cause_data[memory_item] = {
                        'cpu_data': result['cpu_data'],
                        'memory_data': result['memory_data'],
                        'duration_data': result['latency_data']
                    }
                if result['latency_anomaly']:
                    latency_item = service_name + '.networkLatency'
                    latency_candidates.append(latency_item)
                    anomaly_list.append(result['anomaly_data'])
                    # å­˜å‚¨å»¶è¿Ÿæ ¹å› æ•°æ®
                    root_cause_data[latency_item] = {
                        'duration_data': result['latency_data']
                    }

    # æŸ¥è¯¢jvmChaosçš„æƒ…å†µ
    jvm_list = []
    anomaly = analyze_gc(normal_start, normal_end, "inventory", False)
    if anomaly:
        jvm_list.append('inventory.jvmChaos')
        evidences_dict['inventory.jvmChaos'].append(
            "inventoryæœåŠ¡æ£€æµ‹åˆ°JVM GCå¼‚å¸¸ï¼Œå¯èƒ½å­˜åœ¨JVM Chaosé—®é¢˜"
        )

    fre = get_frequency(cpu_list, memory_list, latency_candidates, jvm_list)

    # ä»latencyå€™é€‰æœåŠ¡ä¸­ç­›é€‰æœ€ä¸‹æ¸¸åº”ç”¨
    # 1. æå–å€™é€‰æœåŠ¡ä¸­çš„åº”ç”¨å
    candidate_services = [item.split('.')[0] for item in latency_candidates]

    # 2. æ„å»ºå€™é€‰æœåŠ¡ä¹‹é—´çš„ä¸‹æ¸¸å…³ç³»
    candidate_downstreams = {s: [] for s in candidate_services}
    for caller, callee in calls_relations:
        if caller in candidate_services and callee in candidate_services:
            candidate_downstreams[caller].append(callee)

    # 3. ç­›é€‰å€™é€‰æœåŠ¡ä¸­æ²¡æœ‰ä¸‹æ¸¸çš„åº”ç”¨ï¼ˆæœ€ä¸‹æ¸¸ï¼‰
    most_downstream_in_candidates = [
        s for s in candidate_services
        if not candidate_downstreams[s]  # ä¸‹æ¸¸åˆ—è¡¨ä¸ºç©º
    ]

    # 4. ç”Ÿæˆæ–°çš„latencyå€™é€‰åˆ—è¡¨ï¼ˆåªä¿ç•™æœ€ä¸‹æ¸¸åº”ç”¨ï¼‰
    serveice_list = [
        item for item in latency_candidates
        if item.split('.')[0] in most_downstream_in_candidates
    ]

    # 5. é’ˆå¯¹frontendåº”ç”¨ï¼Œåˆ¤æ–­æ˜¯å¦å­˜åœ¨å»¶è¿Ÿ
    for item in latency_candidates:
        if item.split('.')[0] == "frontend":
            service = item.split('.')[0]
            latency = get_span_latency(log_client, PROJECT_NAME, LOGSTORE_NAME, service, start_str.strip(), end_str.strip(), False)
            if latency:
                serveice_list = [service + '.networkLatency']
                evidences_dict[service + '.networkLatency'].append(
                    "frontendæœåŠ¡æ£€æµ‹åˆ°Spanå»¶è¿Ÿå¼‚å¸¸ï¼Œè¢«é€‰ä¸ºå€™é€‰æ ¹å› "
                )

    if len(cpu_list) > 1:
        cpu_list = find_anomalies(cpu_list, root_cause_data)

    print(f"ğŸ¯ cpuå€™é€‰æœåŠ¡åˆ—è¡¨: {cpu_list}")
    print(f"ğŸ¯ memoryå€™é€‰æœåŠ¡åˆ—è¡¨: {memory_list}")
    print(f"ğŸ¯ latencyå€™é€‰æœåŠ¡åˆ—è¡¨: {serveice_list}")
    print(f"ğŸ¯ jvmChaoså€™é€‰æœåŠ¡åˆ—è¡¨: {jvm_list}")

    # ç»¼åˆåˆ¤æ–­æ ¹å› 
    # 1. æå–cpuå’Œmemoryåˆ—è¡¨ä¸­çš„æ‰€æœ‰å”¯ä¸€æœåŠ¡
    cpu_services = {item.split('.')[0] for item in cpu_list}
    memory_services = {item.split('.')[0] for item in memory_list}
    all_non_latency_services = cpu_services.union(memory_services)

    # 2. æå–latencyåˆ—è¡¨ä¸­çš„æ‰€æœ‰æœåŠ¡
    service_services = {item.split('.')[0] for item in serveice_list}

    # 3. æ ¹æ®è§„åˆ™åˆå¹¶æ ¹å› 
    if len(service_services) > 0 and len(all_non_latency_services) > 1:
        # å¦‚æœcpuå’Œmemoryå­˜åœ¨å¤šä¸ªæœåŠ¡ï¼Œåªä¿ç•™åœ¨latencyåˆ—è¡¨ä¸­å‡ºç°çš„æœåŠ¡
        filtered_cpu = [item for item in cpu_list if item.split('.')[0] in service_services]
        filtered_memory = [item for item in memory_list if item.split('.')[0] in service_services]
        combined = filtered_cpu + filtered_memory + serveice_list + jvm_list
        # è®°å½•ç­›é€‰è¯æ®
        for item in combined:
            evidences_dict[item].append(
                f"å› åŒæ—¶å­˜åœ¨äºlatencyåˆ—è¡¨å’Œcpu/memoryåˆ—è¡¨ä¸­ï¼Œ{item}è¢«ä¿ç•™ä¸ºå€™é€‰æ ¹å› "
            )
    else:
        # å¦åˆ™ç›´æ¥åˆå¹¶æ‰€æœ‰åˆ—è¡¨
        combined = cpu_list + memory_list + serveice_list + jvm_list

    service_root_causes = {}  # å­˜å‚¨æ¯ä¸ªæœåŠ¡çš„æœ€é«˜ä¼˜å…ˆçº§æ ¹å› 
    priority = {'memory': 4, 'cpu': 3, 'jvmChaos': 2, 'networkLatency': 1}  # ä¼˜å…ˆçº§æ˜ å°„

    for item in combined:
        # è§£ææœåŠ¡åå’Œæ ¹å› ç±»å‹
        parts = item.split('.')
        if len(parts) != 2:
            continue  # è·³è¿‡æ ¼å¼å¼‚å¸¸çš„é¡¹
        service, cause_type = parts[0], parts[1]

        # ä»…å¤„ç†å·²çŸ¥ç±»å‹
        if cause_type not in priority:
            continue

        # æ›´æ–°å½“å‰æœåŠ¡çš„æœ€é«˜ä¼˜å…ˆçº§æ ¹å› 
        if service not in service_root_causes:
            # æœåŠ¡é¦–æ¬¡å‡ºç°ï¼Œç›´æ¥è®°å½•
            service_root_causes[service] = (priority[cause_type], item)
        else:
            # æ¯”è¾ƒä¼˜å…ˆçº§ï¼Œä¿ç•™æ›´é«˜çš„
            current_prio, _ = service_root_causes[service]
            if priority[cause_type] > current_prio:
                service_root_causes[service] = (priority[cause_type], item)

    # æå–æœ€ç»ˆæ ¹å› ï¼ˆåªä¿ç•™æ¯ä¸ªæœåŠ¡çš„æœ€é«˜ä¼˜å…ˆçº§é¡¹ï¼‰
    root_causes = [item for (_, item) in service_root_causes.values()]

    # æ ¹æ®serviceå‡ºç°é¢‘ç‡ç­›é€‰æ ¹å› ï¼Œåªä¿ç•™å‡ºç°æ¬¡æ•°æœ€å¤šçš„serviceçš„æ ¹å› 
    if root_causes:
        # ç­›é€‰å‡ºé¢‘ç‡æœ€é«˜çš„serviceå¯¹åº”çš„æ ¹å› 
        root_causes = [item for item in root_causes if item.split('.')[0] in fre]
        print(f"ğŸ¯ æŒ‰é¢‘ç‡ç­›é€‰åçš„æ ¹å› åˆ—è¡¨: {root_causes}")

    # ä¿ç•™æ‰€æœ‰æ ¹å› ä¸­ä¼˜å…ˆçº§æœ€é«˜çš„æ ¹å› 
    priority_causes = ""
    current_prio = 0
    for item in root_causes:
        parts = item.split('.')
        if len(parts) != 2:
            continue  # è·³è¿‡æ ¼å¼å¼‚å¸¸çš„é¡¹
        service, cause_type = parts[0], parts[1]
        if priority[cause_type] > current_prio:
            current_prio = priority[cause_type]
            priority_causes = cause_type
    root_causes = [item for item in root_causes if item.split('.')[1] == priority_causes]
    print(f"ğŸ¯ æŒ‰ä¼˜å…ˆçº§ç­›é€‰åçš„æ ¹å› åˆ—è¡¨: {root_causes}")

    # å½“å­˜åœ¨å¤šä¸ªå»¶è¿Ÿå€™é€‰æ ¹å› ä¸”ä¸å­˜åœ¨å…¶ä»–ç±»å‹æ ¹å› æ—¶ï¼ŒæŒ‰ç…§å»¶è¿Ÿä¸Šå‡å¹…åº¦ç­›é€‰Latency
    if len(cpu_list) == 0 and len(memory_list) == 0 and len(jvm_list) == 0 and len(root_causes) > 0:
        print("âš ï¸ ä»…å­˜åœ¨Latencyå¼‚å¸¸ï¼Œå¼€å§‹è®¡ç®—ä¸Šå‡å¹…åº¦ç­›é€‰æ ¹å› ")
        root_causes, evidences_dict = get_only_anomaly(anomaly_list, root_causes, evidences_dict)

    # å¤„ç† inventory çš„æƒ…å†µ
    if len(root_causes) > 0 and root_causes[0].split('.')[0] == "inventory":
        root_causes = ["inventory.jvmChaos"]
        evidences_dict["inventory.jvmChaos"].append(
            "inventoryæœåŠ¡çš„æ ¹å› è¢«ç¡®å®šä¸ºjvmChaos"
        )

    # å¤„ç† currency çš„æƒ…å†µ
    if len(root_causes) > 0 and root_causes[0] == "currency.cpu":
        flag = get_span_error(log_client, PROJECT_NAME, LOGSTORE_NAME, "currency", start_str.strip(), end_str.strip())
        if flag:
            print("ğŸ” è·å– currency æœåŠ¡ç½‘ç»œå¼‚å¸¸æ•°æ®...")
            root_causes = ["currency.networkLatency"]
            evidences_dict["currency.networkLatency"].append(
                "currencyæœåŠ¡æ£€æµ‹åˆ°ç½‘ç»œå¼‚å¸¸ï¼Œæ ¹å› ä»CPUå¼‚å¸¸è°ƒæ•´ä¸ºç½‘ç»œå»¶è¿Ÿå¼‚å¸¸"
            )

    # å¤„ç† frontend å’Œ checkout çš„æƒ…å†µ
    if latency == False and len(root_causes) > 0 and root_causes[0] in ['frontend.networkLatency', 'checkout.networkLatency']:
        services = []
        if root_causes[0].split('.')[0] == "frontend":
            services = ["ad", "recommendation", "checkout", "cart", "currency", "product-catalog"]
        elif root_causes[0].split('.')[0] == "checkout":
            services = ["product-catalog", "cart", "payment", "shipping", "email", "currency", "quote"]
        latency_candidates = []
        anomaly_list: List[Dict[str, Any]] = []
        for service in services:
            flag, before, target, after, _ = get_log(log_client, PROJECT_NAME, LOGSTORE_NAME, service,
                                                      start_str.strip(), end_str.strip(), False)
            if flag:
                print(f"ğŸ” è·å– {service} æœåŠ¡ç½‘ç»œå»¶è¿Ÿæ•°æ®...")
                latency_candidates.append(service + '.networkLatency')
                anomaly_list.append({
                    "service": service,
                    "before": before,
                    "target": target,
                    "after": after
                })
                evidences_dict[service + '.networkLatency'].append(
                    f"{service}æœåŠ¡æ£€æµ‹åˆ°ç½‘ç»œå»¶è¿Ÿå¼‚å¸¸ï¼Œå€¼ä¸º{target}"
                )
        # å¦‚æœåªå­˜åœ¨1-2ä¸ªæœåŠ¡ç–‘ä¼¼ä¸Šå‡ï¼Œåˆ™ä¸æ˜¯checkoutæˆ–frontendçš„é—®é¢˜
        if len(latency_candidates) < 3:
            root_causes, evidences_dict = get_only_anomaly(anomaly_list, latency_candidates, evidences_dict)

    if len(root_causes) == 0:
        print("âš ï¸ æ ¹å› åˆ—è¡¨ä¸ºç©ºï¼Œå¼€å§‹æŸ¥è¯¢å°‘è§æƒ…å†µ")
        target_service = "inventory"
        cpu_anomaly = analyze_cpu(normal_start, normal_end, target_service, False)
        memory_anomaly = analyze_memory(normal_start, normal_end, target_service, False)
        print(f"CPUå¼‚å¸¸: {cpu_anomaly}, Memoryå¼‚å¸¸: {memory_anomaly}")
        if cpu_anomaly[0] or memory_anomaly[0]:
            root_causes.append(target_service + '.jvmChaos')
            evidences_dict[target_service + '.jvmChaos'].append(
                f"{target_service}æœåŠ¡åœ¨æ ¹å› åˆ—è¡¨ä¸ºç©ºçš„æƒ…å†µä¸‹è¢«æ£€æµ‹åˆ°å¼‚å¸¸ï¼Œè¢«ç¡®å®šä¸ºjvmChaosé—®é¢˜"
            )
    print(f"ğŸ¯ ç­›é€‰åçš„æ ¹å› : {root_causes}")

    # æ”¶é›†æœ€ç»ˆè¯æ®
    final_evidences = []
    for cause in root_causes:
        if cause in evidences_dict:
            final_evidences.extend(evidences_dict[cause])

    # å»é‡å¹¶ä¿æŒé¡ºåº
    seen = set()
    final_evidences = [e for e in final_evidences if not (e in seen or seen.add(e))]

    return root_causes, root_cause_data, final_evidences

#å¤„ç†ç°è‰²æ•…éšœ
def analyze_grey_failure(normal_start, normal_end, candidate_root_causes):
    anomaly_list: List[Dict[str, Any]] = []
    show = False
    cpu_list = []
    memory_list = []
    serveice_list = []
    combined = []
    root_cause_data = {}
    evidences_dict = defaultdict(list)  # å­˜å‚¨æ¯ä¸ªæ ¹å› çš„è¯æ®
    start_str = normal_start.replace(tzinfo=timezone(timedelta(hours=8))).strftime('%Y-%m-%d %H:%M:%S')
    end_str = normal_end.replace(tzinfo=timezone(timedelta(hours=8))).strftime('%Y-%m-%d %H:%M:%S')

    def process_one_service(service, normal_start, normal_end):
        result = {
            'service': service,
            'cpu_anomaly': False,
            'memory_anomaly': False
        }
        print(f"ğŸ¯ Limiting analysis to candidate service: {service}")

        # 4. æŸ¥è¯¢CPUæ•°æ®
        print(f"ğŸ” æŸ¥è¯¢ {service} æœåŠ¡CPUæ•°æ®...")
        cpu_anomaly, max_cpu, cpu_data = analyze_cpu(normal_start, normal_end, service, show)
        result['cpu_data'] = cpu_data
        result['max_cpu'] = max_cpu
        if cpu_anomaly and max_cpu > 30.0:
            # è®°å½•CPUå¼‚å¸¸è¯æ®
            evidences_dict[service + '.cpu'].append(
                f"{service}çš„CPUä½¿ç”¨ç‡å‡ºç°å¼‚å¸¸ï¼Œæœ€å¤§å€¼è¾¾åˆ°{max_cpu}%"
            )
            result['cpu_anomaly'] = True

        # 5. æŸ¥è¯¢Memoryæ•°æ®
        print(f"ğŸ” æŸ¥è¯¢ {service} æœåŠ¡Memoryæ•°æ®...")
        if service == "email":
            result['memory_anomaly'] = False
            result['memory_data'] = []
        else:
            memory_anomaly, max_memory, memory_data = analyze_memory(normal_start, normal_end, service, show)
            result['memory_data'] = memory_data
            result['max_memory'] = max_memory
            if memory_anomaly and max_memory > 15.0:
                # è®°å½•å†…å­˜å¼‚å¸¸è¯æ®
                evidences_dict[service + '.memory'].append(
                    f"{service}çš„å†…å­˜ä½¿ç”¨ç‡å‡ºç°å¼‚å¸¸ï¼Œæœ€å¤§å€¼è¾¾åˆ°{max_memory}%"
                )
                result['memory_anomaly'] = True
        return result

    total_services = []
    for candidate in candidate_root_causes:
        if '.' in candidate and candidate.endswith('.cpu'):
            service = candidate.split('.')[0]
            if service[1] == '-' or service == "load-generator":
                continue
            total_services.append(service)

    with ThreadPoolExecutor() as executor:
        futures = [
            executor.submit(process_one_service, service, normal_start, normal_end) for service in total_services
        ]
        for future in as_completed(futures):
            result = future.result()
            service_name = result['service']
            if result['cpu_anomaly']:
                cpu_item = service_name + '.cpu'
                cpu_list.append(cpu_item)
                root_cause_data[cpu_item] = {
                    'cpu_data': result['cpu_data'],
                    'memory_data': result['memory_data'],
                }
            if result['memory_anomaly']:
                memory_item = service_name + '.memory'
                memory_list.append(memory_item)
                root_cause_data[memory_item] = {
                    'cpu_data': result['cpu_data'],
                    'memory_data': result['memory_data'],
                }

    print(f"ğŸ¯ cpuå€™é€‰æœåŠ¡åˆ—è¡¨: {cpu_list}")
    print(f"ğŸ¯ memoryå€™é€‰æœåŠ¡åˆ—è¡¨: {memory_list}")
    if len(cpu_list) > 1:
        cpu_list = find_anomalies(cpu_list, root_cause_data)
    disk_list = []
    networkloss_list = []
    if len(cpu_list + memory_list) == 0:
        def process_one_service_ecs(service, normal_start, normal_end):
            result = {
                'service': service,
                'cpu_anomaly': False,
                'memory_anomaly': False,
                'disk_anomaly': False
            }
            print(f"ğŸ¯ Limiting analysis to candidate service: {service}")

            # 1. æŸ¥è¯¢CPUæ•°æ®
            print(f"ğŸ” æŸ¥è¯¢ {service} æœåŠ¡CPUæ•°æ®...")
            cpu_anomaly, max_cpu = analyze_ecs_cpu(normal_start, normal_end, service, show)
            if cpu_anomaly and max_cpu > 30.0:
                evidences_dict[service + '.cpu'].append(
                    f"{service}çš„CPUä½¿ç”¨ç‡å‡ºç°å¼‚å¸¸ï¼Œæœ€å¤§å€¼è¾¾åˆ°{max_cpu}%"
                )
                result['cpu_anomaly'] = True

            # 2. æŸ¥è¯¢Memoryæ•°æ®
            print(f"ğŸ” æŸ¥è¯¢ {service} æœåŠ¡Memoryæ•°æ®...")
            # emailæœåŠ¡å†…å­˜é•¿æœŸå­˜åœ¨OOM
            if service == "email":
                result['memory_anomaly'] = False
            else:
                memory_anomaly, max_memory = analyze_ecs_memory(normal_start, normal_end, service, show)
                if memory_anomaly and max_memory > 30.0:
                    evidences_dict[service + '.memory'].append(
                        f"{service}çš„å†…å­˜ä½¿ç”¨ç‡å‡ºç°å¼‚å¸¸ï¼Œæœ€å¤§å€¼è¾¾åˆ°{max_memory}%"
                    )
                    result['memory_anomaly'] = True

            # 3. æŸ¥è¯¢Diskæ•°æ®
            print(f"ğŸ” æŸ¥è¯¢ {service} æœåŠ¡Diskæ•°æ®...")
            disk_anomaly, max_disk = analyze_ecs_disk(normal_start, normal_end, service, show)
            if disk_anomaly and max_disk > 30.0:
                disk_list.append(service + '.disk')
                evidences_dict[service + '.disk'].append(
                    f"{service}çš„ç£ç›˜ä½¿ç”¨ç‡å‡ºç°å¼‚å¸¸ï¼Œæœ€å¤§å€¼è¾¾åˆ°{max_disk}%"
                )
                result['disk_anomaly'] = True

            # 4. è·å–ç½‘ç»œå¼‚å¸¸
            anomaly = analyze_network(normal_start, normal_end, service, False)
            if anomaly >= 2:
                evidences_dict[service + '.networkLoss'].append(
                    f"{service}çš„ç½‘ç»œä¸¢åŒ…æ¬¡æ•°è¿‡å¤šï¼Œå­˜åœ¨ç½‘ç»œå¼‚å¸¸"
                )
                networkloss_list.append(service + '.networkLoss')
                result['network_anomaly'] = True
            return result

        total_servies = []
        for candidate in candidate_root_causes:
            if '.' in candidate and candidate.endswith('.cpu'):
                service = candidate.split('.')[0]
                if service[1] != '-':
                    continue
                total_servies.append(service)

        with ThreadPoolExecutor() as executor:
            futures = [
                executor.submit(process_one_service_ecs, service, normal_start, normal_end) for service in total_servies
            ]
            for future in as_completed(futures):
                result = future.result()
                service_name = result['service']
                if result['cpu_anomaly']:
                    cpu_list.append(service_name + '.cpu')
                if result['memory_anomaly']:
                    memory_list.append(service_name + '.memory')

        root_causes = cpu_list + memory_list + disk_list + networkloss_list
        print(f"ğŸ¯ ecs cpuå€™é€‰æœåŠ¡åˆ—è¡¨: {cpu_list}")
        print(f"ğŸ¯ ecs memoryå€™é€‰æœåŠ¡åˆ—è¡¨: {memory_list}")
        print(f"ğŸ¯ ecs diskå€™é€‰æœåŠ¡åˆ—è¡¨: {disk_list}")
        print(f"ğŸ¯ ecs ç½‘ç»œå¼‚å¸¸æœåŠ¡åˆ—è¡¨: {networkloss_list}")

    service_root_causes = {}  # å­˜å‚¨æ¯ä¸ªæœåŠ¡çš„æœ€é«˜ä¼˜å…ˆçº§æ ¹å› 
    priority = {'memory': 4, 'cpu': 3, 'disk': 2, 'networkLoss': 1}  # ä¼˜å…ˆçº§æ˜ å°„
    combined = cpu_list + memory_list + disk_list + networkloss_list
    for item in combined:
        # è§£ææœåŠ¡åå’Œæ ¹å› ç±»å‹
        parts = item.split('.')
        if len(parts) != 2:
            continue  # è·³è¿‡æ ¼å¼å¼‚å¸¸çš„é¡¹
        service, cause_type = parts[0], parts[1]

        # ä»…å¤„ç†å·²çŸ¥ç±»å‹
        if cause_type not in priority:
            continue

        # æ›´æ–°å½“å‰æœåŠ¡çš„æœ€é«˜ä¼˜å…ˆçº§æ ¹å› 
        if service not in service_root_causes:
            # æœåŠ¡é¦–æ¬¡å‡ºç°ï¼Œç›´æ¥è®°å½•
            service_root_causes[service] = (priority[cause_type], item)
        else:
            # æ¯”è¾ƒä¼˜å…ˆçº§ï¼Œä¿ç•™æ›´é«˜çš„
            current_prio, _ = service_root_causes[service]
            if priority[cause_type] > current_prio:
                service_root_causes[service] = (priority[cause_type], item)

    # æå–æœ€ç»ˆæ ¹å› ï¼ˆåªä¿ç•™æ¯ä¸ªæœåŠ¡çš„æœ€é«˜ä¼˜å…ˆçº§é¡¹ï¼‰
    root_causes = [item for (_, item) in service_root_causes.values()]

    # æ²¡æœ‰æ ¹å› ï¼Œåˆ™æŸ¥è¯¢podKillçš„æƒ…å†µ
    if len(root_causes) == 0:
        podKilled = []
        for candidate in candidate_root_causes:
            if '.' in candidate and candidate.endswith('.cpu'):
                service = candidate.split('.')[0]
                if service != 'checkout' and service != "frontend" and service != "product-catalog":
                    continue
                hostname_list = get_instance(log_client, PROJECT_NAME, LOGSTORE_NAME, service,
                                             start_str.strip(), end_str.strip())
                start = datetime.strptime(start_str.strip(), "%Y-%m-%d %H:%M:%S").replace(tzinfo=timezone(timedelta(hours=8)))
                end = datetime.strptime(end_str.strip(), "%Y-%m-%d %H:%M:%S").replace(tzinfo=timezone(timedelta(hours=8)))
                num = 0
                for hostname in hostname_list:
                    print(f"ğŸ” Found hostname {hostname}, processing...")
                    flag, _ = get_pod(start, end, hostname, True)
                    if not flag:
                        num += 1
                if 0 < num <= 2 and len(hostname_list) > 2:
                    print(f"âœ… podKilled")
                    evidences_dict[service + '.podKiller'].append(
                        f"{service}æœåŠ¡çš„podåœ¨æ£€æµ‹æ—¶é—´æ®µå†…è¢«ç»ˆæ­¢"
                    )
                    podKilled.append(service + '.podKiller')
        root_causes = podKilled

    if len(root_causes) == 0:
        print("âš ï¸ æ ¹å› åˆ—è¡¨ä¸ºç©ºï¼Œå¼€å§‹æŸ¥è¯¢å°‘è§æƒ…å†µ")
        target_service = "inventory"
        cpu_anomaly = analyze_cpu(normal_start, normal_end, target_service, False)
        memory_anomaly = analyze_memory(normal_start, normal_end, target_service, False)
        print(f"CPUå¼‚å¸¸: {cpu_anomaly}, Memoryå¼‚å¸¸: {memory_anomaly}")
        if cpu_anomaly[0] or memory_anomaly[0]:
            evidences_dict[target_service + '.jvmChaos'].append(
                f"{target_service}æœåŠ¡åœ¨æ£€æµ‹æ—¶é—´æ®µå†…å­˜åœ¨cpuå’Œmemoryå¼‚å¸¸æ³¢åŠ¨ï¼Œå¯èƒ½æ˜¯jvmchaosæ‰€å¯¼è‡´çš„"
            )
            root_causes.append(target_service + '.jvmChaos')
    print(f"ğŸ¯ ç­›é€‰åçš„æ ¹å› åˆ—è¡¨: {root_causes}")

    if len(root_causes) == 0:
        flag, _, _, _, _ = get_log(log_client, PROJECT_NAME, LOGSTORE_NAME, "email", start_str.strip(), end_str.strip(), True, False)
        cpu_anomaly, _, _ = analyze_cpu(normal_start, normal_end, "email", show, False)
        if flag and cpu_anomaly:
            root_causes = ["email.memory"]
            evidences_dict["email.memory"].append(
                f"emailæœåŠ¡åœ¨æ£€æµ‹æ—¶é—´æ®µå†…å­˜åœ¨cpuå¼‚å¸¸ä¸‹é™ï¼Œä¸”å»¶è¿Ÿä¸‹é™ï¼Œå¯èƒ½æ˜¯OOMæ‰€å¯¼è‡´çš„"
            )

    if len(root_causes) == 0:
        print("âš ï¸ æ ¹å› åˆ—è¡¨ä¾æ—§ä¸ºç©ºï¼ŒæŸ¥è¯¢å»¶è¿Ÿæƒ…å†µ")
        def process_one_service(service, normal_start, normal_end, isMedian=True):
            result = {
                'service': service,
                'latency_anomaly': False,
                'anomaly_data': None,
                'latency_data': None  # å­˜å‚¨å»¶è¿Ÿæ•°æ®
            }
            # è·å–å»¶è¿Ÿæ•°æ®
            print(f"ğŸ¯ Limiting analysis to candidate service: {service}")
            flag, before, target, after, duration_data = get_log(log_client, PROJECT_NAME, LOGSTORE_NAME, service,
                                                                 start_str.strip(),
                                                                 end_str.strip(), False)
            result['latency_data'] = duration_data
            if flag:
                evidences_dict[service + '.networkLatency'].append(
                    f"{service}æœåŠ¡æ£€æµ‹åˆ°ç½‘ç»œå»¶è¿Ÿå¼‚å¸¸ï¼Œå¼‚å¸¸å€¼ä¸º{target}ï¼Œç›¸æ¯”æ­£å¸¸åŒºé—´å‰åŠæ®µ({before})å’ŒååŠæ®µ({after})å­˜åœ¨æ˜æ˜¾ä¸Šå‡ï¼"
                )
                result['latency_anomaly'] = True
                result['anomaly_data'] = {
                    "service": service,
                    "before": before,
                    "target": target,
                    "after": after,
                }
            return result

        # å¹¶è¡Œ
        total_services = []
        for candidate in candidate_root_causes:
            if '.' in candidate and candidate.endswith('.cpu'):
                service = candidate.split('.')[0]
                if service[1] == '-' or service == "load-generator":
                    continue
                total_services.append(service)
        latency_candidates = []
        anomaly_list = []
        with ThreadPoolExecutor() as executor:
            futures = [
                executor.submit(process_one_service, service, normal_start, normal_end) for service in
                total_services
            ]
            for future in as_completed(futures):
                result = future.result()
                service_name = result['service']
                if result['latency_anomaly']:
                    latency_item = service_name + '.networkLatency'
                    latency_candidates.append(latency_item)
                    anomaly_list.append(result['anomaly_data'])

        root_causes, evidences_dict = get_only_anomaly(anomaly_list, latency_candidates, evidences_dict)
    print(f"ğŸ¯ ç­›é€‰åçš„æ ¹å› åˆ—è¡¨: {root_causes}")

    # æ”¶é›†æœ€ç»ˆè¯æ®
    final_evidences = []
    for cause in root_causes:
        if cause in evidences_dict:
            final_evidences.extend(evidences_dict[cause])

    # å»é‡å¹¶ä¿æŒé¡ºåº
    seen = set()
    final_evidences = [e for e in final_evidences if not (e in seen or seen.add(e))]
    return root_causes, root_cause_data, final_evidences

# å¤„ç†é”™è¯¯è¿‡å¤šæŠ¥è­¦
def analyze_error_problem(normal_start, normal_end, candidate_root_causes):
    error_list = []
    anomaly_list: List[Dict[str, Any]] = []
    root_cause_data = {}
    evidences_dict = defaultdict(list)  # å­˜å‚¨æ¯ä¸ªæ ¹å› çš„è¯æ®
    start_str = normal_start.replace(tzinfo=timezone(timedelta(hours=8))).strftime('%Y-%m-%d %H:%M:%S')
    end_str = normal_end.replace(tzinfo=timezone(timedelta(hours=8))).strftime('%Y-%m-%d %H:%M:%S')

    def process_one_service(service, normal_start, normal_end):
        result = {
            'service': service,
            'error_anomaly': False,
            'anomaly_data': None
        }
        # 1. æŸ¥è¯¢æŠ¥é”™æ•°æ®
        print(f"ğŸ” æŸ¥è¯¢ {service} æœåŠ¡æŠ¥é”™æ•°æ®...")
        start_str = normal_start.replace(tzinfo=timezone(timedelta(hours=8))).strftime('%Y-%m-%d %H:%M:%S')
        end_str = normal_end.replace(tzinfo=timezone(timedelta(hours=8))).strftime('%Y-%m-%d %H:%M:%S')
        error_anomaly, _, target_error, _ = get_error(log_client, PROJECT_NAME, LOGSTORE_NAME, service,
                                                      start_str.strip(), end_str.strip())
        if error_anomaly and target_error > 2.0:
            result['error_anomaly'] = True
            result['anomaly_data'] = {
                "service": service,
                "error": target_error,
            }
            evidences_dict[service + '.Failure'].append(f"{service}æœåŠ¡åœ¨æ£€æµ‹æ—¶é—´æ®µå†…æŠ¥é”™æ¬¡æ•°è¿‡å¤šï¼ŒæŠ¥é”™æ¬¡æ•°ä¸º{target_error}")
        return result

    total_services = []
    for candidate in candidate_root_causes:
        if '.' in candidate and candidate.endswith('.cpu'):
            service = candidate.split('.')[0]
            if service[1] == '-' or service == "load-generator":
                continue
            total_services.append(service)

    with ThreadPoolExecutor() as executor:
        futures = [
            executor.submit(process_one_service, service, normal_start, normal_end) for service in total_services
        ]
        for future in as_completed(futures):
            result = future.result()
            if result['error_anomaly']:
                error_list.append(result['service'] + '.Failure')
                anomaly_list.append(result['anomaly_data'])

    print(f"ğŸ¯ æŠ¥é”™å€™é€‰æœåŠ¡åˆ—è¡¨: {error_list}")
    # ä»å€™é€‰æœåŠ¡ä¸­ç­›é€‰æœ€ä¸‹æ¸¸åº”ç”¨
    # 1. æå–å€™é€‰æœåŠ¡ä¸­çš„åº”ç”¨å
    candidate_services = [item.split('.')[0] for item in error_list]

    # 2. æ„å»ºå€™é€‰æœåŠ¡ä¹‹é—´çš„ä¸‹æ¸¸å…³ç³»
    candidate_downstreams = {s: [] for s in candidate_services}
    for caller, callee in calls_relations:
        if caller in candidate_services and callee in candidate_services:
            candidate_downstreams[caller].append(callee)

    # 3. ç­›é€‰å€™é€‰æœåŠ¡ä¸­æ²¡æœ‰ä¸‹æ¸¸çš„åº”ç”¨ï¼ˆæœ€ä¸‹æ¸¸ï¼‰
    most_downstream_in_candidates = [
        s for s in candidate_services
        if not candidate_downstreams[s]  # ä¸‹æ¸¸åˆ—è¡¨ä¸ºç©º
    ]

    # 4. ç”Ÿæˆæ–°çš„å€™é€‰åˆ—è¡¨ï¼ˆåªä¿ç•™æœ€ä¸‹æ¸¸åº”ç”¨ï¼‰
    serveice_list = [
        item for item in error_list
        if item.split('.')[0] in most_downstream_in_candidates
    ]
    root_causes = serveice_list
    if len(root_causes) > 1:
        amplitude_dict = {}
        for anomaly in anomaly_list:
            service = anomaly['service']
            if service + '.Failure' not in root_causes:
                continue
            # å‡è®¾beforeã€targetä¸ºæ•°å€¼åˆ—è¡¨ï¼Œå–å¹³å‡å€¼è®¡ç®—
            try:
                target = anomaly['error']
                amplitude_dict[service] = target
            except Exception as e:
                print(f"âŒ è·å–targetå¤±è´¥: {e}")

        if amplitude_dict:
            # æ‰¾åˆ°å¹…åº¦æœ€å¤§çš„æœåŠ¡
            max_amplitude_service = max(amplitude_dict.items(), key=lambda x: x[1])[0]
            # åªä¿ç•™è¯¥æœåŠ¡çš„æ ¹å› 
            root_causes = [item for item in root_causes if item.split('.')[0] == max_amplitude_service]
            print(f"ğŸ¯ æŒ‰æœ€å¤§ä¸Šå‡å¹…åº¦ç­›é€‰åçš„æ ¹å› : {root_causes}")
    if len(root_causes) > 0 and root_causes[0].split('.')[0] == "inventory":
        print(f"ğŸ” æŸ¥è¯¢ inventory æœåŠ¡CPUæ•°æ®...")
        cpu_anomaly, max_cpu, _ = analyze_cpu(normal_start, normal_end, "inventory", False)
        if cpu_anomaly:
            root_causes = ["inventory.jvmChaos"]
            evidences_dict["inventory" + '.jvmChaos'].append(
                f"inventoryæœåŠ¡åœ¨æ£€æµ‹æ—¶é—´æ®µå†…é”™è¯¯è¿‡å¤šä¸”ä¼´æœ‰CPUå¼‚å¸¸æ³¢åŠ¨ï¼Œå¯èƒ½æ˜¯jvmChaoså¯¼è‡´çš„")
        flag, _, _, _, _ = get_log(log_client, PROJECT_NAME, LOGSTORE_NAME, "inventory", start_str.strip(), end_str.strip(), True, False)
        if flag:
            root_causes = ["inventory.jvmChaos"]
            evidences_dict["inventory" + '.jvmChaos'].append(
                f"inventoryæœåŠ¡åœ¨æ£€æµ‹æ—¶é—´æ®µå†…é”™è¯¯è¿‡å¤šä¸”å¤§é‡è¯·æ±‚å»¶è¿Ÿå¼‚å¸¸é™ä½ï¼Œå¯èƒ½æ˜¯jvmChaoså¯¼è‡´çš„")
    print(f"ğŸ¯ ç­›é€‰åçš„æ ¹å› åˆ—è¡¨: {root_causes}")

    # æ”¶é›†æœ€ç»ˆè¯æ®
    final_evidences = []
    for cause in root_causes:
        if cause in evidences_dict:
            final_evidences.extend(evidences_dict[cause])

    # å»é‡å¹¶ä¿æŒé¡ºåº
    seen = set()
    final_evidences = [e for e in final_evidences if not (e in seen or seen.add(e))]
    return root_causes, root_cause_data, final_evidences
